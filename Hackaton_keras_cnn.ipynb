{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8aa9d-cef0-401b-8d34-1fc38da8d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras, os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d33e2b-e71b-4e12-8575-06fda2194579",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f286d4be-d4a8-439d-b514-8c639352c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: data augmentation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12f7a9-ace1-4148-83eb-179a59d72d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: I assume \n",
    "# - you have objects train_images and train_labels (and corresponding test_*) with dimentions: \n",
    "#   train_images.shape = (n examples, px width, px height)\n",
    "#   train_labels.shape = (n examples, )\n",
    "# - pixel values are NORMALISED --> smaller values work better ususally\n",
    "# - We have two classes that are more or less balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50463d-a8ec-48f6-9b90-ecffb26df13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to 3D for keras imput (if you have not already) \n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "# do the same for test_images \n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels) # just turns vector labels to a 1-hot array, not sure if you need it but probably \n",
    "# same for test_labels\n",
    "\n",
    "_, img_dim1, img_dim2, img_dim3 = train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de145bde-da5c-44c2-8024-5f1c3841457c",
   "metadata": {},
   "source": [
    "### Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eacd9c-123f-4157-801e-a8bd95c2ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN model \n",
    "\n",
    "# Hyperparameters (PLAY KIDS, PLAY)\n",
    "num_filters = 8 \n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "activation_inner, activation_outer = 'relu', 'sigmoid' # 'softmax'\n",
    "\n",
    "# Sequential stacks the layers together \n",
    "cnn_model = tf.keras.Sequential([\n",
    "    \n",
    "    # First Convolution and Pooling Layers\n",
    "    tf.keras.layers.Conv2D(num_filters, filter_size, \n",
    "                           input_shape=(img_dim1, img_dim2, img_dim3),\n",
    "                           activation=activation_inner),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=pool_size),\n",
    "    # tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    # Add second convolution and pooling Layers (try without first)\n",
    "    # tf.keras.layers.Conv2D(num_filters2, filter_size2, activation=activation_inner),\n",
    "    # tf.keras.layers.MaxPooling2D(pool_size=pool_size2), \n",
    "\n",
    "    # Dropout example\n",
    "    tf.keras.layers.Dropout(0.2), # Nice for preventing overfitting \n",
    "\n",
    "    tf.keras.layers.Flatten(), \n",
    "    # Can add more Dense layers here too often done\n",
    "    tf.keras.layers.Dense(1, activation=activation_outer), # 2 categories no? \n",
    "])\n",
    "\n",
    "cnn_model.summary()\n",
    "#tf.keras.utils.plot_model(cnn_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91f608-f0f0-4ba0-9053-c35411e196b3",
   "metadata": {},
   "source": [
    "### Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561044c-9f2b-417d-94cf-936ff67901bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'adam' # this is usually quite good, I would not touch for now \n",
    "loss_func = 'binary_crossentropy' # we have two categories no..? or 'categorical_crossentropy'\n",
    "# try also tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) for sparse labels\n",
    "metrics = ['accuracy'] # Can use F1 if you have very unbalanced classes, not sure \n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer, \n",
    "    loss = loss_func,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc46892-e73b-488d-a244-6c6d6b8afbf0",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524547ac-5406-4e53-95da-564e5bb9161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100 # Iterations, keep this low if you are overfitting, or you can try to rely on the callbacks I define below\n",
    "\n",
    "# Define some to prevent overfitting callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"cnn_stocazzo.best_epoch\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_images, \n",
    "    train_labels, # just turns vector labels to a 1-hot array, not sure if you need it \n",
    "    epochs = n_epochs, \n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d6797-dc47-42af-8c83-1feaeca829a4",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e8386-15ff-4f90-b902-e3615ee5b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I plot accuracy you can plot loss too if helpful \n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'test accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "test_loss, test_acc = cnn_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(test_acc)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "ax = ax.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1336693-cb29-4a7f-804a-bee032eb7ae9",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b1b12-8c9b-430d-9022-077f816794b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save_weights('cnn_stocazzo.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
